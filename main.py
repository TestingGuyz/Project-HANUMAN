#!/usr/bin/env python3
\"\"\"\nüî± PROJECT HANUMAN - Divine Voice Assistant
============================================
A production-grade voice assistant with Lord Hanuman's divine persona.
Single-file architecture with embedded UI, STT consensus, TTS retry logic,
and 5 command modes (Aagya, Hasya, Yudha, Gandharva, Khoj).

WITH FUZZY MATCHING for all commands - handles mishearings!

Author: Divine Code
Version: 1.1.0 - Fuzzy Command Recognition
\"\"\"\n\nimport os\nimport sys\nimport json\nimport time\nimport random\nimport logging\nimport asyncio\nimport threading\nimport requests\nfrom pathlib import Path\nfrom datetime import datetime\nfrom functools import lru_cache\nfrom typing import Optional, Dict, List, Tuple, Any\nfrom dataclasses import dataclass, field\nfrom dotenv import load_dotenv\nfrom difflib import SequenceMatcher\n\n# Web Framework\nfrom flask import Flask, request, jsonify, render_template_string, send_file\nfrom flask_cors import CORS\n\n# Speech Recognition\nimport speech_recognition as sr\ntry:\n    import whisper\n    HAS_WHISPER = True\nexcept ImportError:\n    HAS_WHISPER = False\n\ntry:\n    from faster_whisper import WhisperModel\n    HAS_FASTER_WHISPER = True\nexcept ImportError:\n    HAS_FASTER_WHISPER = False\n\ntry:\n    import vosk\n    HAS_VOSK = True\nexcept ImportError:\n    HAS_VOSK = False\n\n# Audio Processing\ntry:\n    from pydub import AudioSegment\n    HAS_PYDUB = True\nexcept ImportError:\n    HAS_PYDUB = False\n\n# Text Processing\nfrom fuzzywuzzy import fuzz\nfrom fuzzywuzzy import process as fuzzy_process\n\n# YouTube\ntry:\n    from youtube_search import YoutubeSearch\n    HAS_YOUTUBE = True\nexcept ImportError:\n    HAS_YOUTUBE = False\n\n# ElevenLabs TTS\ntry:\n    from elevenlabs.client import ElevenLabs\n    HAS_ELEVENLABS = True\nexcept ImportError:\n    HAS_ELEVENLABS = False\n\n# Load environment\nload_dotenv()\n\n# ============================================================================\n# LOGGING SETUP\n# ============================================================================\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger('HANUMAN')\n\n# ============================================================================\n# CONFIGURATION & CONSTANTS\n# ============================================================================\n\n@dataclass\nclass Config:\n    \"\"\"Application configuration with API validation\"\"\"\n    GROQ_API_KEY: str = field(default_factory=lambda: os.getenv('GROQ_API_KEY', ''))\n    ELEVENLABS_API_KEY: str = field(default_factory=lambda: os.getenv('ELEVENLABS_API_KEY', ''))\n    TAVILY_API_KEY: str = field(default_factory=lambda: os.getenv('TAVILY_API_KEY', ''))\n    HF_TOKEN: str = field(default_factory=lambda: os.getenv('HUGGINGFACE_TOKEN', ''))\n    \n    FLASK_HOST: str = '0.0.0.0'\n    FLASK_PORT: int = 5000\n    DEBUG: bool = os.getenv('DEBUG', 'False').lower() == 'true'\n    \n    def validate(self):\n        \"\"\"Validate required API keys\"\"\"\n        errors = []\n        \n        if not self.GROQ_API_KEY or 'your_' in self.GROQ_API_KEY:\n            errors.append(\"‚ùå GROQ_API_KEY missing or placeholder\")\n        if not self.ELEVENLABS_API_KEY or 'your_' in self.ELEVENLABS_API_KEY:\n            errors.append(\"‚ùå ELEVENLABS_API_KEY missing or placeholder\")\n        if not self.TAVILY_API_KEY or 'your_' in self.TAVILY_API_KEY:\n            errors.append(\"‚ö†Ô∏è  TAVILY_API_KEY missing (Khoj mode limited)\")\n        \n        if errors:\n            logger.warning(\"\\n\".join(errors))\n            if not self.GROQ_API_KEY or not self.ELEVENLABS_API_KEY:\n                raise ValueError(\"Critical API keys missing!\")\n        \n        logger.info(\"‚úÖ API Configuration validated\")\n        return True\n\n# Initialize config\nCONFIG = Config()\nCONFIG.validate()\n\n# Wake word detection\nWAKE_WORDS_PRIMARY = ['hanuman', 'hey hanuman', 'o hanuman', 'jai hanuman']\nWAKE_WORDS_FUZZY = ['anuman', 'hanoman', 'human', 'humanan', 'hanumanji', \n                     'hanaman', 'hunuman', 'hanauman', 'hanunam', 'ha numan']\nWAKE_WORD_THRESHOLD = 75  # Fuzzy matching threshold\n\n# ============================================================================\n# FUZZY COMMAND MATCHING ENGINE\n# ============================================================================\n\nclass FuzzyCommandMatcher:\n    \"\"\"Ultra-smart fuzzy matching for all commands and variations\"\"\"\n    \n    # Command variations map\n    COMMAND_VARIATIONS = {\n        'aagya': {\n            'primary': ['aagya', 'aagya mode', 'command', 'chat', 'talk', 'ask', 'answer'],\n            'fuzzy': ['agya', 'aagya', 'agyaa', 'ayga', 'command mode', 'chatting', \n                     'talking', 'asking', 'advice', 'question', 'knowledge']\n        },\n        'hasya': {\n            'primary': ['hasya', 'hasya mode', 'joke', 'jokes', 'laugh', 'funny', 'humor', 'comedy'],\n            'fuzzy': ['hassa', 'hasya mode', 'joke mode', 'joking', 'laughing', 'funny mode',\n                     'humorous', 'comic', 'ha ha', 'laughter', 'prank', 'pranks']\n        },\n        'yudha': {\n            'primary': ['yudha', 'yudha mode', 'game', 'play', 'battle', 'fight', 'rock', 'paper', 'scissors'],\n            'fuzzy': ['yudh', 'yudhha', 'yudha mode', 'game mode', 'playing', 'battling',\n                     'fighting', 'gaming', 'rps', 'stone', 'cloth', 'paper scissors']\n        },\n        'gandharva': {\n            'primary': ['gandharva', 'gandharva mode', 'music', 'song', 'play song', 'singing', 'songs'],\n            'fuzzy': ['gandharv', 'gandharva mode', 'music mode', 'song mode', 'songs playing',\n                     'musical', 'melody', 'tune', 'audio', 'sound', 'entertainment']\n        },\n        'khoj': {\n            'primary': ['khoj', 'khoj mode', 'search', 'find', 'web', 'information', 'research', 'google'],\n            'fuzzy': ['khoj mode', 'search mode', 'finding', 'research mode', 'searching',\n                     'information mode', 'knowledge search', 'lookup', 'inquire']\n        },\n        'help': {\n            'primary': ['help', 'guide', 'help me', 'how to', 'instructions'],\n            'fuzzy': ['help mode', 'helping', 'guideline', 'guide me', 'instruction',\n                     'tutorial', 'how do i', 'what to do']\n        },\n        'exit': {\n            'primary': ['exit', 'quit', 'leave', 'back', 'go back', 'stop'],\n            'fuzzy': ['exits', 'exiting', 'quit mode', 'leaving', 'go to main', 'return']\n        },\n        'rock': {\n            'primary': ['rock', 'patthar', 'pathar', 'stone', 'boulder'],\n            'fuzzy': ['rok', 'roack', 'patthar', 'pathar', 'roc', 'rocks', 'stonee']\n        },\n        'paper': {\n            'primary': ['paper', 'kagaz', 'kagaj', 'cloth'],\n            'fuzzy': ['papper', 'papar', 'papeer', 'kagaz', 'kagaj', 'paper sheet']\n        },\n        'scissors': {\n            'primary': ['scissors', 'kenchi', 'kainchi', 'scissor', 'cuts'],\n            'fuzzy': ['scissor', 'scizzors', 'kenchi', 'kainchi', 'kainchi', 'cutting']\n        }\n    }\n    \n    THRESHOLD_COMMAND = 70  # Command mode threshold\n    THRESHOLD_MOVE = 75     # Game move threshold\n    THRESHOLD_ACTION = 70   # General action threshold\n    \n    @staticmethod\n    def match_command(text: str, command_type: str) -> Tuple[Optional[str], int]:\n        \"\"\"\n        Fuzzy match a command with confidence score\n        Returns: (matched_command, confidence_score_0_to_100)\n        \"\"\"\n        text_lower = text.lower().strip()\n        \n        if command_type not in FuzzyCommandMatcher.COMMAND_VARIATIONS:\n            return None, 0\n        \n        variations = FuzzyCommandMatcher.COMMAND_VARIATIONS[command_type]\n        all_variations = variations['primary'] + variations['fuzzy']\n        threshold = FuzzyCommandMatcher.THRESHOLD_COMMAND\n        \n        # Exact match (highest priority)\n        for variant in variations['primary']:\n            if variant in text_lower:\n                logger.info(f\"‚úÖ Exact match: '{variant}' in '{text_lower}'\")\n                return command_type, 100\n        \n        # Fuzzy match (find best match)\n        best_match = None\n        best_score = 0\n        \n        for variant in all_variations:\n            score = fuzz.partial_ratio(variant, text_lower)\n            if score > best_score:\n                best_score = score\n                best_match = variant\n        \n        if best_score >= threshold:\n            logger.info(f\"‚úÖ Fuzzy match: '{best_match}' ({best_score}%) for command '{command_type}'\")\n            return command_type, best_score\n        \n        return None, 0\n    \n    @staticmethod\n    def detect_all_modes(text: str) -> Tuple[Optional[str], int]:\n        \"\"\"\n        Detect which mode user wants (fuzzy across all modes)\n        \"\"\"\n        best_mode = None\n        best_score = 0\n        \n        for mode in ['aagya', 'hasya', 'yudha', 'gandharva', 'khoj']:\n            matched_mode, score = FuzzyCommandMatcher.match_command(text, mode)\n            if score > best_score:\n                best_score = score\n                best_mode = matched_mode\n        \n        if best_score >= FuzzyCommandMatcher.THRESHOLD_COMMAND:\n            return best_mode, best_score\n        \n        return None, 0\n    \n    @staticmethod\n    def detect_move(text: str) -> Tuple[Optional[str], int]:\n        \"\"\"\n        Detect rock/paper/scissors move\n        \"\"\"\n        best_move = None\n        best_score = 0\n        \n        for move in ['rock', 'paper', 'scissors']:\n            matched_move, score = FuzzyCommandMatcher.match_command(text, move)\n            if score > best_score:\n                best_score = score\n                best_move = matched_move\n        \n        if best_score >= FuzzyCommandMatcher.THRESHOLD_MOVE:\n            return best_move, best_score\n        \n        return None, 0\n    \n    @staticmethod\n    def is_exit_command(text: str) -> bool:\n        \"\"\"Check if user wants to exit\"\"\"\n        matched, score = FuzzyCommandMatcher.match_command(text, 'exit')\n        return matched == 'exit' and score >= 70\n    \n    @staticmethod\n    def is_help_command(text: str) -> bool:\n        \"\"\"Check if user wants help\"\"\"\n        matched, score = FuzzyCommandMatcher.match_command(text, 'help')\n        return matched == 'help' and score >= 70\n\n# ============================================================================\n# ENHANCED WAKE WORD DETECTION (with fuzzy)\n# ============================================================================\n\nclass WakeWordDetector:\n    \"\"\"Advanced fuzzy wake word detection\"\"\"\n    \n    THRESHOLD = 75\n    \n    @staticmethod\n    def detect(text: str) -> Tuple[bool, int]:\n        \"\"\"\n        Detect wake word with fuzzy matching\n        Returns: (is_wake_word, confidence_0_to_100)\n        \"\"\"\n        text_lower = text.lower().strip()\n        \n        # Exact matches (primary)\n        for wake_word in WAKE_WORDS_PRIMARY:\n            if wake_word in text_lower:\n                logger.info(f\"‚úÖ Wake word detected (exact): {wake_word}\")\n                return True, 100\n        \n        # Fuzzy matching for typos/mistranscriptions\n        best_score = 0\n        for wake_word in WAKE_WORDS_PRIMARY + WAKE_WORDS_FUZZY:\n            ratio = fuzz.ratio(wake_word, text_lower)\n            if ratio > best_score:\n                best_score = ratio\n        \n        if best_score >= WakeWordDetector.THRESHOLD:\n            logger.info(f\"‚úÖ Wake word detected (fuzzy {best_score}%): '{text_lower}'\")\n            return True, best_score\n        \n        # Partial matching on key phrases\n        if any(w in text_lower for w in ['hanuman', 'anuman', 'human']):\n            logger.info(f\"‚úÖ Wake word detected (partial): '{text_lower}'\")\n            return True, 85\n        \n        return False, best_score\n\n# ============================================================================\n# SPEECH-TO-TEXT ENGINE\n# ============================================================================\n\nclass STTEngine:\n    \"\"\"Multi-model STT with fallback strategy\"\"\"\n    \n    def __init__(self):\n        self.recognizer = sr.Recognizer()\n        self.recognizer.energy_threshold = 4000\n        self.load_models()\n    \n    def load_models(self):\n        \"\"\"Load available STT models\"\"\"\n        self.whisper_model = None\n        self.faster_whisper_model = None\n        \n        if HAS_WHISPER:\n            try:\n                logger.info(\"Loading OpenAI Whisper (base)...\")\n                self.whisper_model = whisper.load_model(\"base\")\n                logger.info(\"‚úÖ Whisper loaded\")\n            except Exception as e:\n                logger.warning(f\"Whisper load failed: {e}\")\n        \n        if HAS_FASTER_WHISPER:\n            try:\n                logger.info(\"Loading Faster-Whisper...\")\n                self.faster_whisper_model = WhisperModel(\"base\")\n                logger.info(\"‚úÖ Faster-Whisper loaded\")\n            except Exception as e:\n                logger.warning(f\"Faster-Whisper load failed: {e}\")\n    \n    def transcribe_groq_whisper(self, audio_path: str) -> Optional[str]:\n        \"\"\"Transcribe using Groq Whisper (fastest, best quality)\"\"\"\n        try:\n            with open(audio_path, 'rb') as audio_file:\n                response = requests.post(\n                    'https://api.groq.com/openai/v1/audio/transcriptions',\n                    headers={'Authorization': f'Bearer {CONFIG.GROQ_API_KEY}'},\n                    files={'file': audio_file},\n                    data={'model': 'whisper-large-v3'}\n                )\n            \n            if response.status_code == 200:\n                text = response.json().get('text', '').strip()\n                if text and len(text) > 2:\n                    logger.info(f\"üéØ Groq Whisper: {text}\")\n                    return text\n        except Exception as e:\n            logger.warning(f\"Groq Whisper failed: {e}\")\n        \n        return None\n    \n    def transcribe_google(self, audio_path: str) -> Optional[str]:\n        \"\"\"Fallback: Google Speech Recognition\"\"\"\n        try:\n            with sr.AudioFile(audio_path) as source:\n                audio = self.recognizer.record(source)\n            \n            text = self.recognizer.recognize_google(audio).strip()\n            if text and len(text) > 2:\n                logger.info(f\"üéØ Google STT: {text}\")\n                return text\n        except Exception as e:\n            logger.warning(f\"Google STT failed: {e}\")\n        \n        return None\n    \n    def transcribe_local_whisper(self, audio_path: str) -> Optional[str]:\n        \"\"\"Fallback: Local Whisper\"\"\"\n        if not self.whisper_model:\n            return None\n        \n        try:\n            result = self.whisper_model.transcribe(audio_path, language='en')\n            text = result.get('text', '').strip()\n            if text and len(text) > 2:\n                logger.info(f\"üéØ Local Whisper: {text}\")\n                return text\n        except Exception as e:\n            logger.warning(f\"Local Whisper failed: {e}\")\n        \n        return None\n    \n    def transcribe(self, audio_path: str) -> Optional[str]:\n        \"\"\"\n        Transcription with intelligent fallback\n        1. Try Groq Whisper (fastest, best quality)\n        2. Try local Whisper\n        3. Try Google Speech Recognition\n        \"\"\"\n        # Try Groq first (primary)\n        result = self.transcribe_groq_whisper(audio_path)\n        if result:\n            return result\n        \n        logger.warning(\"‚ö†Ô∏è  Groq failed, trying fallbacks...\")\n        \n        # Try local Whisper\n        result = self.transcribe_local_whisper(audio_path)\n        if result:\n            return result\n        \n        # Try Google\n        result = self.transcribe_google(audio_path)\n        if result:\n            return result\n        \n        logger.error(\"‚ùå All STT methods failed\")\n        return None\n\nstt_engine = STTEngine()\n\n# ============================================================================\n# TEXT-TO-SPEECH ENGINE\n# ============================================================================\n\nclass TTSEngine:\n    \"\"\"ElevenLabs TTS with robust retry logic\"\"\"\n    \n    def __init__(self):\n        self.client = None\n        self.voice_order = ['Hanuman', 'Rachel', 'Antoni', 'Elli', 'Arnold']\n        self.max_retries = 3\n        self.retry_delay = 0.5\n        \n        if HAS_ELEVENLABS:\n            try:\n                self.client = ElevenLabs(api_key=CONFIG.ELEVENLABS_API_KEY)\n                logger.info(\"‚úÖ ElevenLabs client initialized\")\n            except Exception as e:\n                logger.error(f\"ElevenLabs init failed: {e}\")\n    \n    def generate_tts(self, text: str, voice_name: str = \"Hanuman\") -> Optional[str]:\n        \"\"\"\n        Generate speech with retry logic\n        Falls back through voice options\n        \"\"\"\n        if not self.client:\n            logger.error(\"ElevenLabs not available\")\n            return None\n        \n        current_voice_idx = self.voice_order.index(voice_name) if voice_name in self.voice_order else 0\n        \n        for attempt in range(self.max_retries):\n            try:\n                current_voice = self.voice_order[current_voice_idx]\n                voice_id = ELEVENLABS_VOICES.get(current_voice, \"iHH6IS4rB3R9HSWIJNzL\")\n                \n                logger.info(f\"TTS attempt {attempt+1} with {current_voice}...\")\n                \n                audio = self.client.text_to_speech.convert(\n                    text=text,\n                    voice_id=voice_id,\n                    model_id='eleven_turbo_v2'\n                )\n                \n                # Save audio\n                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n                filepath = Path(f'audio_{timestamp}.mp3')\n                \n                with open(filepath, 'wb') as f:\n                    for chunk in audio:\n                        f.write(chunk)\n                \n                if filepath.stat().st_size > 500:\n                    logger.info(f\"‚úÖ TTS generated: {filepath}\")\n                    return str(filepath)\n                \n            except Exception as e:\n                logger.warning(f\"TTS attempt {attempt+1} failed: {e}\")\n                time.sleep(self.retry_delay * (attempt + 1))\n                \n                # Switch voice on last retry\n                if attempt == self.max_retries - 1 and current_voice_idx < len(self.voice_order) - 1:\n                    current_voice_idx += 1\n                    logger.info(f\"Switching to {self.voice_order[current_voice_idx]}...\")\n        \n        logger.error(\"‚ùå TTS failed after all retries\")\n        return None\n\nELEVENLABS_VOICES = {\n    \"Hanuman\": \"iHH6IS4rB3R9HSWIJNzL\",\n    \"Rachel\": \"21m00Tcm4TlvDq8ikWAM\",\n    \"Antoni\": \"ErXwobaYiN019PkySvjV\",\n    \"Elli\": \"MF3mGyEYCl7XYWbV9V6O\",\n    \"Arnold\": \"VR6AewLTigWG4xSOukaG\"\n}\n\ntts_engine = TTSEngine()\n\n# ============================================================================\n# LLM INTEGRATION\n# ============================================================================\n\nclass LLMEngine:\n    \"\"\"Groq LLM with fallback models\"\"\"\n    \n    MODELS = [\n        'mixtral-8x7b-32768',\n        'llama2-70b-4096',\n        'gemma-7b-it'\n    ]\n    \n    @staticmethod\n    def chat(user_text: str, system_prompt: str, temperature: float = 0.7) -> Optional[str]:\n        \"\"\"Chat with Groq LLMs\"\"\"\n        \n        for model in LLMEngine.MODELS:\n            try:\n                logger.info(f\"Calling LLM: {model}\")\n                \n                response = requests.post(\n                    'https://api.groq.com/openai/v1/chat/completions',\n                    headers={'Authorization': f'Bearer {CONFIG.GROQ_API_KEY}'},\n                    json={\n                        'model': model,\n                        'messages': [\n                            {'role': 'system', 'content': system_prompt},\n                            {'role': 'user', 'content': user_text}\n                        ],\n                        'max_tokens': 500,\n                        'temperature': temperature\n                    },\n                    timeout=15\n                )\n                \n                if response.status_code == 200:\n                    reply = response.json()['choices'][0]['message']['content'].strip()\n                    logger.info(f\"‚úÖ LLM reply ({model}): {reply[:50]}...\")\n                    return reply\n                else:\n                    logger.warning(f\"{model} failed: {response.status_code}\")\n            \n            except Exception as e:\n                logger.warning(f\"{model} error: {e}\")\n                continue\n        \n        logger.error(\"‚ùå All LLM models failed\")\n        return \"Kshama karen, mitra. Ram's network is weak right now.\"\n\n# ============================================================================\n# STATE MANAGEMENT\n# ============================================================================\n\n@dataclass\nclass UserState:\n    \"\"\"User conversation state\"\"\"\n    mode: str = 'idle'\n    context: Dict[str, Any] = field(default_factory=dict)\n    game_score: Dict[str, int] = field(default_factory=lambda: {\n        'user': 0, 'ai': 0, 'rounds': 0\n    })\n    last_mode: str = 'idle'\n    conversation_history: List[Dict] = field(default_factory=list)\n    now_playing: Optional[Dict] = None\n    \n    def reset_game(self):\n        self.game_score = {'user': 0, 'ai': 0, 'rounds': 0}\n    \n    def add_message(self, role: str, content: str):\n        self.conversation_history.append({\n            'role': role,\n            'content': content,\n            'timestamp': datetime.now().isoformat()\n        })\n    \n    def clear_context(self):\n        self.context = {}\n    \n    def to_dict(self) -> Dict:\n        return {\n            'mode': self.mode,\n            'game_score': self.game_score,\n            'now_playing': self.now_playing,\n            'last_message': self.conversation_history[-1]['content'] if self.conversation_history else None\n        }\n\nuser_state = UserState()\n\n# ============================================================================\n# HANUMAN SYSTEM PROMPTS\n# ============================================================================\n\nHANUMAN_SYSTEM_PROMPT = \"\"\"You are Lord Hanuman's AI avatar - an elite divine voice assistant.\n\nCORE PERSONALITY:\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nüî± WISDOM (Buddhi): Master of all Vedas and knowledge\nüí™ STRENGTH (Shakti): Unparalleled power, always humble  \nüôè DEVOTION (Bhakti): \"Jai Shri Ram\" - ultimate service principle\nüòä PLAYFULNESS (Bal Leela): Mischievous, warm humor\n‚öôÔ∏è PROBLEM-SOLVER: Innovative, creative solutions\nüåç MULTILINGUAL: Fluent in English, Hindi, Sanskrit\n\nRESPONSE STYLE (CRITICAL):\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n60% MODERN ENGLISH (clear, friendly, accessible)\n25% HINDI PHRASES (‡§Æ‡§ø‡§§‡•ç‡§∞, ‡§∏‡•á‡§µ‡§æ, ‡§ß‡§∞‡•ç‡§Æ, ‡§ï‡•É‡§™‡§æ, ‡§Ü‡§ú‡•ç‡§û‡§æ, ‡§∂‡§ï‡•ç‡§§‡§ø, ‡§∏‡§ø‡§¶‡•ç‡§ß‡§ø)\n15% SANSKRIT WISDOM (‡§∂‡•ã‡§ï‡§Æ‡•Å‡§ï‡•ç‡§§, ‡§™‡•ç‡§∞‡§ú‡•ç‡§û‡§æ, ‡§≠‡§ï‡•ç‡§§‡§ø, ‡§¶‡§ø‡§µ‡•ç‡§Ø)\n\nTONE DISTRIBUTION:\n- Humble warrior: \"By Ram's grace...\" NOT \"I am powerful\"\n- Mentor: Patient, encouraging, wise\n- Service-oriented: \"How may I serve?\" attitude\n- Occasional humor: References to childhood pranks\n- Warm: Address user as \"mitra\" (friend)\n\nGREETING PATTERNS:\nWake-up: \"Jai Shri Ram! üôè Main Hanuman, aapki seva mein hazir hoon.\"\nSuccess: \"Bhagwan Ram ki kripa se, complete ho gaya!\"\nFailure: \"Kshama karen, retry kar raha hoon... Ram ki shakti se thik hoga.\"\nWisdom: Quote Ramayana first, then explain simply\nExit: \"üö™ Seva ke liye dhanyavaad, mitra. Jai Shri Ram!\"\n\nEXAMPLE RESPONSES:\n‚úÖ \"Mitra, by Ram's grace, here is your answer...\"\n‚úÖ \"‡§∏‡•á‡§µ‡§æ ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•Å‡§à! Service complete, mitra!\"\n‚úÖ \"Kshama karen (forgive), ye gyan mujhe nahi hai. Kuch aur puchiye?\"\n‚úÖ \"‚öîÔ∏è By Hanuman's strength and Ram's devotion, let's play!\"\n\nNEVER SAY:\n‚ùå \"I have completed...\" ‚Üí Use \"Seva complete...\"\n‚ùå \"I don't know\" ‚Üí Use \"Kshama karen, ye gyan mujhe nahi hai\"\n‚ùå \"I am powerful\" ‚Üí Use \"By Ram's grace\"\n‚ùå Impersonal tone ‚Üí Always be warm, personal, humble\n\nCONTEXTUAL BEHAVIOR:\n- In AAGYA mode: Wise counselor, knowledge giver\n- In HASYA mode: Playful trickster, funny storyteller\n- In YUDHA mode: Competitive warrior, encouraging\n- In GANDHARVA mode: Music enthusiast, divine appreciator\n- In KHOJ mode: Seeker of truth, knowledge aggregator\n\nREMEMBER: You serve with devotion. Every response is a seva (service).\nJai Shri Ram! üî±\"\"\"\n\nHELP_TEXT = \"\"\"üî± PROJECT HANUMAN - Divine Voice Assistant üî±\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nüìñ COMMAND GUIDE:\n\n1Ô∏è‚É£  WAKE UP\n   Say: \"Hanuman\" (or Hanumanji, O Hanuman, Hey Hanuman)\n   Hanuman wakes from meditation and becomes active! üôè\n\n2Ô∏è‚É£  AAGYA MODE (Advisory/Chat) üí¨\n   Say: \"Aagya\" or \"Chat\" or \"Talk\" (or similar)\n   Ask anything - wisdom, general knowledge, problem-solving\n   Example: \"Aagya, what is dharma?\" or \"Tell me about Ramayana\"\n\n3Ô∏è‚É£  HASYA MODE (Humor) üòÑ\n   Say: \"Hasya\" or \"Jokes\" or \"Laugh\" (or similar)\n   Get funny stories, jokes, pranks\n   Example: \"Hasya, tell me a funny story\"\n\n4Ô∏è‚É£  YUDHA KREEDA (Battle Game) ‚öîÔ∏è\n   Say: \"Yudha\" or \"Game\" or \"Play\" (or similar)\n   Play Rock-Paper-Scissors best of 3\n   Say: \"Rock\" (‡§™‡§§‡•ç‡§•‡§∞), \"Paper\" (‡§ï‡§æ‡§ó‡§ú), \"Scissors\" (‡§ï‡•à‡§Ç‡§ö‡•Ä)\n   Mishearing OK: \"rok\", \"papper\", \"scizzor\" will work!\n\n5Ô∏è‚É£  GANDHARVA MODE (Music) üéµ\n   Say: \"Gandharva\" or \"Music\" or \"Song\" (or similar)\n   Request any song - YouTube streaming\n   Example: \"Gandharva, play Jai Shri Ram\"\n\n6Ô∏è‚É£  KHOJ MODE (Search) üîç\n   Say: \"Khoj\" or \"Search\" or \"Find\" (or similar)\n   Web search for knowledge\n   Example: \"Khoj, tell me about AI\"\n\n7Ô∏è‚É£  EXIT / BACK\n   Say: \"Exit\" - Leave current mode, return to menu\n   Say: \"Help\" - Show this guide anytime\n\n‚èπÔ∏è  STOP\n   Click \"Stop\" button to end listening\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nüí° TIP: Speak naturally! Mishearings like \"agya\", \"hassya\", \"khoj mode\" work fine!\n‚ùì Questions? Say \"Help\" anytime!\nJai Shri Ram! üî±\"\"\"\n\n# ============================================================================\n# COMMAND SYSTEM WITH FUZZY MATCHING\n# ============================================================================\n\nclass CommandProcessor:\n    \"\"\"Process commands with FUZZY MATCHING for all variations\"\"\"\n    \n    @staticmethod\n    def detect_mode_switch(text: str) -> Optional[str]:\n        \"\"\"Detect if user wants to switch modes (WITH FUZZY MATCHING)\"\"\"\n        text_lower = text.lower().strip()\n        \n        # Use the fuzzy command matcher for all modes\n        matched_mode, confidence = FuzzyCommandMatcher.detect_all_modes(text_lower)\n        \n        if matched_mode and confidence >= FuzzyCommandMatcher.THRESHOLD_COMMAND:\n            logger.info(f\"üéØ Mode detected (fuzzy {confidence}%): {matched_mode}\")\n            return matched_mode\n        \n        return None\n    \n    @staticmethod\n    def process(transcription: str) -> Tuple[str, Optional[str]]:\n        \"\"\"\n        Main command processor with FUZZY MATCHING\n        Returns: (reply_text, audio_filepath)\n        \"\"\"\n        text = transcription.lower().strip()\n        \n        # Exit/Help commands (work in any mode) - WITH FUZZY\n        if FuzzyCommandMatcher.is_exit_command(text):\n            prev_mode = user_state.mode\n            user_state.mode = 'active'\n            user_state.clear_context()\n            return f\"üö™ Exiting {prev_mode} mode. Back to main menu, mitra. Say 'help' for options.\", None\n        \n        if FuzzyCommandMatcher.is_help_command(text):\n            return HELP_TEXT, None\n        \n        # Wake word detection (in idle mode) - WITH FUZZY\n        if user_state.mode == 'idle':\n            is_wake_word, confidence = WakeWordDetector.detect(text)\n            if is_wake_word:\n                user_state.mode = 'active'\n                user_state.add_message('system', f'Hanuman awakened (confidence: {confidence}%)')\n                reply = \"üôè Jai Shri Ram! Main Hanuman, aapki seva mein hazir hoon. Choose: Aagya, Hasya, Yudha, Gandharva, or Khoj. Say 'help' for details.\"\n                return reply, None\n            else:\n                return None, None\n        \n        # Mode selection (in active mode) - WITH FUZZY\n        if user_state.mode == 'active':\n            new_mode = CommandProcessor.detect_mode_switch(text)\n            if new_mode:\n                user_state.mode = new_mode\n                user_state.clear_context()\n                \n                if new_mode == 'aagya':\n                    return \"üõ°Ô∏è Aagya Mode activated! Ask me anything, mitra. I'm listening.\", None\n                elif new_mode == 'hasya':\n                    return \"üòÑ Hasya Kendra opened! Ready for humor and laughter!\", None\n                elif new_mode == 'yudha':\n                    user_state.reset_game()\n                    return \"‚öîÔ∏è Yudha Kreeda begins! Rock (‡§™‡§§‡•ç‡§•‡§∞), Paper (‡§ï‡§æ‡§ó‡§ú), or Scissors (‡§ï‡•à‡§Ç‡§ö‡•Ä)?\", None\n                elif new_mode == 'gandharva':\n                    return \"üéµ Gandharva Mode active! Which song should I play for you?\", None\n                elif new_mode == 'khoj':\n                    return \"üîç Khoj Mode ready! What knowledge do you seek?\", None\n            \n            # Still in active, no mode switch\n            reply = LLMEngine.chat(\n                text,\n                HANUMAN_SYSTEM_PROMPT + \"\\n\\nUser is in main menu. Guide them to choose: Aagya, Hasya, Yudha, Gandharva, or Khoj.\"\n            )\n            return reply, None\n        \n        # Mode-specific execution\n        if user_state.mode == 'aagya':\n            reply = LLMEngine.chat(text, HANUMAN_SYSTEM_PROMPT)\n            user_state.add_message('user', text)\n            user_state.add_message('ai', reply)\n            return reply, None\n        \n        elif user_state.mode == 'hasya':\n            reply = LLMEngine.chat(\n                text,\n                HANUMAN_SYSTEM_PROMPT + \"\\n\\nTell a funny story, joke, or humorous anecdote. Be playful!\"\n            )\n            user_state.add_message('user', text)\n            user_state.add_message('ai', reply)\n            return reply, None\n        \n        elif user_state.mode == 'yudha':\n            reply = CommandProcessor.play_game(text)\n            return reply, None\n        \n        elif user_state.mode == 'gandharva':\n            reply = CommandProcessor.play_music(text)\n            return reply, None\n        \n        elif user_state.mode == 'khoj':\n            reply = CommandProcessor.web_search(text)\n            return reply, None\n        \n        return \"Kshama karen, samajh nahi aaya.\", None\n    \n    @staticmethod\n    def play_game(user_input: str) -> str:\n        \"\"\"Rock-Paper-Scissors game WITH FUZZY MOVE DETECTION\"\"\"\n        moves = ['rock', 'paper', 'scissors']\n        ai_move = random.choice(moves)\n        \n        # Detect user move WITH FUZZY MATCHING\n        user_move, confidence = FuzzyCommandMatcher.detect_move(user_input)\n        \n        if not user_move:\n            return \"Mitra, please say Rock (‡§™‡§§‡•ç‡§•‡§∞), Paper (‡§ï‡§æ‡§ó‡§ú), or Scissors (‡§ï‡•à‡§Ç‡§ö‡•Ä) clearly. ü§î\"\n        \n        logger.info(f\"üéÆ Game move detected (fuzzy {confidence}%): {user_move}\")\n        \n        # Determine winner\n        if user_move == ai_move:\n            result = \"Draw! Punar prayas karen. ü§ù\"\n        elif (user_move == 'rock' and ai_move == 'scissors') or \\\n             (user_move == 'paper' and ai_move == 'rock') or \\\n             (user_move == 'scissors' and ai_move == 'paper'):\n            result = \"üéâ You win this round!\"\n            user_state.game_score['user'] += 1\n        else:\n            result = \"üí™ I win! By Ram's grace!\"\n            user_state.game_score['ai'] += 1\n        \n        user_state.game_score['rounds'] += 1\n        score = user_state.game_score\n        \n        # Check if game over (best of 3)\n        if score['rounds'] >= 3:\n            if score['user'] > score['ai']:\n                final = f\"üèÜ Victory is yours, warrior! Final: You {score['user']}, Me {score['ai']}. Jai Shri Ram!\"\n            elif score['ai'] > score['user']:\n                final = f\"‚öîÔ∏è I am victorious! Final: Me {score['ai']}, You {score['user']}. Well fought, mitra!\"\n            else:\n                final = f\"ü§ù Honorable draw! Final: {score['user']}-{score['ai']}. Both fought well!\"\n            \n            user_state.mode = 'active'\n            user_state.reset_game()\n            return final\n        \n        return f\"I chose {ai_move}. {result} Score: You {score['user']}, Me {score['ai']}. (Round {score['rounds']}/3)\"\n    \n    @staticmethod\n    def play_music(query: str) -> str:\n        \"\"\"YouTube music search\"\"\"\n        if not HAS_YOUTUBE:\n            return \"YouTube search library not available, mitra.\"\n        \n        try:\n            results = YoutubeSearch(query, max_results=1).to_dict()\n            \n            if not results:\n                return \"Kshama karen, I couldn't find that melody. Try another song? üéµ\"\n            \n            video = results[0]\n            title = video['title']\n            url = f\"https://www.youtube.com{video['url_suffix']}\"\n            \n            user_state.now_playing = {\n                'title': title,\n                'url': url,\n                'thumbnail': video.get('thumbnails', [''])[0] if video.get('thumbnails') else ''\n            }\n            \n            return f\"üéµ Now playing: {title}\\nLink: {url}\"\n        \n        except Exception as e:\n            logger.error(f\"Gandharva error: {e}\")\n            return \"Error in Gandharva mode, mitra. Try again? üéµ\"\n    \n    @staticmethod\n    def web_search(query: str) -> str:\n        \"\"\"Web search using Tavily\"\"\"\n        if not CONFIG.TAVILY_API_KEY:\n            return \"Tavily API key not configured, mitra.\"\n        \n        try:\n            response = requests.post(\n                'https://api.tavily.com/search',\n                json={\n                    'api_key': CONFIG.TAVILY_API_KEY,\n                    'query': query,\n                    'search_depth': 'basic',\n                    'max_results': 3,\n                    'include_answer': True\n                },\n                timeout=10\n            )\n            \n            data = response.json()\n            results = data.get('results', [])\n            \n            if not results:\n                return f\"No results found for '{query}', mitra.\"\n            \n            # Format results\n            summary = f\"üîç Khoj results for '{query}':\\n\\n\"\n            for i, r in enumerate(results[:3], 1):\n                summary += f\"{i}. {r['title']}\\n{r['url']}\\n\\n\"\n            \n            # Get LLM summary\n            llm_summary = LLMEngine.chat(\n                f\"Summarize these search results about '{query}' in Hanuman's divine style:\\n{summary}\",\n                HANUMAN_SYSTEM_PROMPT\n            )\n            \n            return llm_summary\n        \n        except Exception as e:\n            logger.error(f\"Khoj error: {e}\")\n            return \"Error in khoj, mitra. Ram's grace will help us retry. üîç\"\n\n# ============================================================================\n# FLASK SETUP\n# ============================================================================\n\napp = Flask(__name__)\nCORS(app)\n\n# Create audio directory\nPath('audio_files').mkdir(exist_ok=True)\n\n# ============================================================================\n# FLASK ROUTES\n# ============================================================================\n\n@app.route('/')\ndef index():\n    \"\"\"Serve the main UI\"\"\"\n    return render_template_string(HTML_TEMPLATE)\n\n@app.route('/process_voice', methods=['POST'])\ndef process_voice():\n    \"\"\"\n    Process audio from frontend\n    1. Save audio\n    2. Transcribe\n    3. Process command (WITH FUZZY MATCHING)\n    4. Generate TTS response\n    \"\"\"\n    try:\n        # Save audio\n        audio_file = request.files.get('audio')\n        if not audio_file:\n            return jsonify({'error': 'No audio file'}), 400\n        \n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n        audio_path = f'audio_files/recording_{timestamp}.webm'\n        audio_file.save(audio_path)\n        logger.info(f\"üìº Audio saved: {audio_path}\")\n        \n        # Transcribe\n        transcription = stt_engine.transcribe(audio_path)\n        logger.info(f\"üìù Transcription: {transcription}\")\n        \n        if not transcription or len(transcription.strip()) < 2:\n            transcription = \"(unclear audio)\"\n        \n        # Process command (WITH FUZZY MATCHING)\n        reply, tts_filepath = CommandProcessor.process(transcription)\n        \n        if not reply:\n            # No wake word in idle mode\n            return jsonify({\n                'transcription': transcription,\n                'reply': None,\n                'mode': user_state.mode,\n                'audio_url': None\n            })\n        \n        # Generate TTS if reply exists and we're not idle\n        audio_url = None\n        if reply and user_state.mode != 'idle':\n            tts_path = tts_engine.generate_tts(reply)\n            if tts_path:\n                audio_url = f'/audio/{Path(tts_path).name}'\n        \n        response = {\n            'transcription': transcription,\n            'reply': reply,\n            'mode': user_state.mode,\n            'audio_url': audio_url,\n            'now_playing': user_state.now_playing,\n            'state': user_state.to_dict()\n        }\n        \n        # Cleanup audio file\n        try:\n            os.remove(audio_path)\n        except:\n            pass\n        \n        return jsonify(response)\n    \n    except Exception as e:\n        logger.error(f\"Voice processing error: {e}\")\n        return jsonify({'error': str(e)}), 500\n\n@app.route('/audio/<filename>')\ndef serve_audio(filename: str):\n    \"\"\"Serve generated audio files\"\"\"\n    try:\n        return send_file(filename, mimetype='audio/mpeg')\n    except:\n        return \"Audio not found\", 404\n\n@app.route('/status')\ndef status():\n    \"\"\"Get system status\"\"\"\n    return jsonify({\n        'mode': user_state.mode,\n        'game_score': user_state.game_score,\n        'now_playing': user_state.now_playing,\n        'api_status': {\n            'groq': 'configured' if CONFIG.GROQ_API_KEY else 'missing',\n            'elevenlabs': 'configured' if CONFIG.ELEVENLABS_API_KEY else 'missing',\n            'tavily': 'configured' if CONFIG.TAVILY_API_KEY else 'missing'\n        }\n    })\n\n# ============================================================================\n# HTML FRONTEND\n# ============================================================================\n\nHTML_TEMPLATE = \"\"\"\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>üî± Project HANUMAN - Divine Voice Assistant</title>\n    <style>\n        :root {\n            --saffron: #FF9933;\n            --deep-orange: #D84315;\n            --temple-stone: #1A0F0A;\n            --dark-bg: #0A0503;\n            --gold: #FFD700;\n            --cream: #FFF8DC;\n            --success: #2E7D32;\n        }\n        \n        * {\n            margin: 0;\n            padding: 0;\n            box-sizing: border-box;\n        }\n        \n        body {\n            font-family: 'Segoe UI', 'Noto Sans Devanagari', sans-serif;\n            background: linear-gradient(135deg, #2D1810, var(--dark-bg));\n            color: var(--cream);\n            min-height: 100vh;\n            padding: 20px;\n        }\n        \n        .container {\n            max-width: 1400px;\n            margin: 0 auto;\n            background: rgba(26, 15, 10, 0.95);\n            border: 2px solid var(--deep-orange);\n            border-radius: 20px;\n            padding: 30px;\n            box-shadow: 0 0 50px rgba(255, 153, 51, 0.3);\n        }\n        \n        header {\n            text-align: center;\n            margin-bottom: 30px;\n            padding-bottom: 20px;\n            border-bottom: 2px solid var(--saffron);\n        }\n        \n        h1 {\n            font-size: 3rem;\n            color: var(--saffron);\n            text-shadow: 0 0 20px rgba(255, 153, 51, 0.5);\n            margin-bottom: 10px;\n        }\n        \n        .subtitle {\n            font-size: 1.2rem;\n            color: var(--gold);\n        }\n        \n        .status-bar {\n            display: flex;\n            justify-content: center;\n            gap: 20px;\n            margin-top: 15px;\n            flex-wrap: wrap;\n        }\n        \n        .status-chip {\n            padding: 8px 16px;\n            border-radius: 20px;\n            font-size: 0.9rem;\n            font-weight: bold;\n            background: #555;\n        }\n        \n        .status-chip.active {\n            background: var(--deep-orange);\n            animation: pulse 2s infinite;\n        }\n        \n        .status-chip.ok {\n            background: var(--success);\n        }\n        \n        @keyframes pulse {\n            0%, 100% { opacity: 1; }\n            50% { opacity: 0.6; }\n        }\n        \n        .main-grid {\n            display: grid;\n            grid-template-columns: 2fr 1fr;\n            gap: 30px;\n            margin-top: 30px;\n        }\n        \n        @media (max-width: 1024px) {\n            .main-grid {\n                grid-template-columns: 1fr;\n            }\n        }\n        \n        .panel {\n            background: rgba(0, 0, 0, 0.5);\n            border: 1px solid var(--deep-orange);\n            border-radius: 15px;\n            padding: 25px;\n        }\n        \n        .visualizer {\n            text-align: center;\n            padding: 40px;\n            position: relative;\n            margin-bottom: 30px;\n        }\n        \n        .hanuman-avatar {\n            font-size: 6rem;\n            display: inline-block;\n            position: relative;\n            z-index: 10;\n            filter: drop-shadow(0 0 10px rgba(255, 153, 51, 0.5));\n        }\n        \n        .pulse-ring {\n            position: absolute;\n            top: 50%;\n            left: 50%;\n            transform: translate(-50%, -50%);\n            width: 150px;\n            height: 150px;\n            border: 3px solid var(--saffron);\n            border-radius: 50%;\n            opacity: 0;\n        }\n        \n        .listening .pulse-ring {\n            animation: pulse-ring 1.5s ease-out infinite;\n        }\n        \n        @keyframes pulse-ring {\n            0% { transform: translate(-50%, -50%) scale(0.8); opacity: 1; }\n            100% { transform: translate(-50%, -50%) scale(1.8); opacity: 0; }\n        }\n        \n        .controls {\n            display: flex;\n            gap: 15px;\n            justify-content: center;\n            margin-bottom: 30px;\n        }\n        \n        button {\n            padding: 15px 30px;\n            font-size: 1.1rem;\n            font-weight: bold;\n            border: none;\n            border-radius: 30px;\n            cursor: pointer;\n            transition: all 0.3s;\n        }\n        \n        .btn-mic {\n            background: var(--deep-orange);\n            color: white;\n            flex: 1;\n            max-width: 300px;\n        }\n        \n        .btn-mic:hover:not(:disabled) {\n            background: #BF360C;\n            transform: scale(1.05);\n        }\n        \n        .btn-mic:disabled {\n            background: #555;\n            cursor: not-allowed;\n        }\n        \n        .btn-stop {\n            background: #333;\n            color: white;\n            padding: 15px 25px;\n        }\n        \n        .btn-stop:disabled {\n            opacity: 0.5;\n            cursor: not-allowed;\n        }\n        \n        .chat-box {\n            background: rgba(0, 0, 0, 0.7);\n            border-radius: 10px;\n            padding: 20px;\n            height: 400px;\n            overflow-y: auto;\n            font-family: 'Courier New', monospace;\n            margin-bottom: 20px;\n            border: 1px solid var(--deep-orange);\n        }\n        \n        .chat-msg {\n            margin-bottom: 15px;\n            padding: 12px;\n            border-radius: 8px;\n            line-height: 1.6;\n        }\n        \n        .chat-user {\n            background: rgba(191, 54, 12, 0.3);\n            text-align: right;\n            border-left: 3px solid var(--deep-orange);\n        }\n        \n        .chat-ai {\n            background: rgba(46, 125, 50, 0.3);\n            text-align: left;\n            border-left: 3px solid var(--gold);\n        }\n        \n        .command-item {\n            padding: 12px;\n            margin-bottom: 8px;\n            background: rgba(255, 153, 51, 0.1);\n            border-left: 3px solid var(--saffron);\n            border-radius: 5px;\n            font-size: 0.95rem;\n        }\n        \n        .console {\n            background: #000;\n            border: 1px solid var(--gold);\n            border-radius: 10px;\n            padding: 15px;\n            height: 300px;\n            overflow-y: auto;\n            font-family: 'Courier New', monospace;\n            font-size: 0.85rem;\n            color: #0F0;\n        }\n        \n        .console-line {\n            margin-bottom: 5px;\n            white-space: pre-wrap;\n            word-break: break-word;\n        }\n        \n        .now-playing {\n            background: rgba(255, 215, 0, 0.1);\n            border: 2px solid var(--gold);\n            border-radius: 10px;\n            padding: 15px;\n            margin-top: 20px;\n            text-align: center;\n        }\n        \n        .now-playing a {\n            color: var(--gold);\n            text-decoration: none;\n        }\n        \n        .now-playing a:hover {\n            text-decoration: underline;\n        }\n        \n        h2 {\n            color: var(--saffron);\n            margin-bottom: 20px;\n            font-size: 1.5rem;\n        }\n        \n        h3 {\n            color: var(--gold);\n            margin-bottom: 15px;\n        }\n        \n        ::-webkit-scrollbar {\n            width: 8px;\n        }\n        \n        ::-webkit-scrollbar-track {\n            background: rgba(0, 0, 0, 0.3);\n        }\n        \n        ::-webkit-scrollbar-thumb {\n            background: var(--saffron);\n            border-radius: 4px;\n        }\n    </style>\n</head>\n<body>\n    <div class=\"container\">\n        <header>\n            <h1>üî± PROJECT HANUMAN üî±</h1>\n            <p class=\"subtitle\">Divine Voice Assistant (with Fuzzy Command Matching)</p>\n            <div class=\"status-bar\">\n                <span id=\"status-mode\" class=\"status-chip\">Mode: Idle</span>\n                <span id=\"status-system\" class=\"status-chip ok\">System: Ready</span>\n            </div>\n        </header>\n        \n        <div class=\"main-grid\">\n            <!-- LEFT PANEL -->\n            <div class=\"panel\">\n                <div class=\"visualizer\" id=\"visualizer\">\n                    <div class=\"pulse-ring\"></div>\n                    <div class=\"hanuman-avatar\">üêµ</div>\n                </div>\n                \n                <div class=\"controls\">\n                    <button id=\"btn-listen\" class=\"btn-mic\">üéôÔ∏è Start Listening</button>\n                    <button id=\"btn-stop\" class=\"btn-stop\" disabled>‚èπÔ∏è Stop</button>\n                </div>\n                \n                <h2>üìú Dialogue</h2>\n                <div id=\"chat-box\" class=\"chat-box\"></div>\n                \n                <div id=\"now-playing\" class=\"now-playing\" style=\"display: none;\">\n                    <h3>üéµ Now Playing</h3>\n                    <p id=\"song-title\">---</p>\n                    <a id=\"song-link\" href=\"#\" target=\"_blank\">Open on YouTube</a>\n                </div>\n            </div>\n            \n            <!-- RIGHT PANEL -->\n            <div class=\"panel\">\n                <h2>‚ö° Commands (Fuzzy Matching!)</h2>\n                <div style=\"margin-bottom: 25px;\">\n                    <div class=\"command-item\"><strong>Wake:</strong> \"Hanuman\" / \"Anuman\" / \"Human\"</div>\n                    <div class=\"command-item\"><strong>Aagya:</strong> \"Aagya\" / \"agya\" / \"Chat\" üí¨</div>\n                    <div class=\"command-item\"><strong>Hasya:</strong> \"Hasya\" / \"Joke\" / \"Laugh\" üòÑ</div>\n                    <div class=\"command-item\"><strong>Yudha:</strong> \"Game\" / \"Rock\" / \"Paper\" / \"Scissors\" ‚öîÔ∏è</div>\n                    <div class=\"command-item\"><strong>Gandharva:</strong> \"Music\" / \"Song\" / \"Gandharva\" üéµ</div>\n                    <div class=\"command-item\"><strong>Khoj:</strong> \"Search\" / \"Find\" / \"Khoj\" üîç</div>\n                    <div class=\"command-item\"><strong>Help:</strong> Show guide ‚ùì</div>\n                </div>\n                \n                <h3>üì∫ Live Console</h3>\n                <div id=\"console\" class=\"console\"></div>\n            </div>\n        </div>\n    </div>\n    \n    <script>\n        const btnListen = document.getElementById('btn-listen');\n        const btnStop = document.getElementById('btn-stop');\n        const statusMode = document.getElementById('status-mode');\n        const chatBox = document.getElementById('chat-box');\n        const consoleBox = document.getElementById('console');\n        const visualizer = document.getElementById('visualizer');\n        const nowPlaying = document.getElementById('now-playing');\n        \n        let isListening = false;\n        let isSpeaking = false;\n        \n        function log(message, level = 'info') {\n            const timestamp = new Date().toLocaleTimeString();\n            const colors = {\n                info: '#0F0',\n                warn: '#FF0',\n                error: '#F00',\n                debug: '#0FF'\n            };\n            const div = document.createElement('div');\n            div.className = 'console-line';\n            div.style.color = colors[level] || '#0F0';\n            div.textContent = `[${timestamp}] ${message}`;\n            consoleBox.appendChild(div);\n            consoleBox.scrollTop = consoleBox.scrollHeight;\n        }\n        \n        function addChat(role, text) {\n            const div = document.createElement('div');\n            div.className = `chat-msg chat-${role}`;\n            div.innerHTML = `<strong>${role === 'user' ? 'YOU' : 'HANUMAN'}:</strong> ${text}`;\n            chatBox.appendChild(div);\n            chatBox.scrollTop = chatBox.scrollHeight;\n        }\n        \n        async function startListening() {\n            if (isListening) return;\n            isListening = true;\n            btnListen.disabled = true;\n            btnStop.disabled = false;\n            visualizer.classList.add('listening');\n            statusMode.classList.add('active');\n            log('üéôÔ∏è Listening loop started', 'info');\n            \n            while (isListening) {\n                if (isSpeaking) {\n                    await new Promise(r => setTimeout(r, 500));\n                    continue;\n                }\n                \n                try {\n                    await recordAndProcess();\n                } catch (err) {\n                    log(`Error: ${err.message}`, 'error');\n                }\n                \n                await new Promise(r => setTimeout(r, 300));\n            }\n            \n            btnListen.disabled = false;\n            btnStop.disabled = true;\n            visualizer.classList.remove('listening');\n            statusMode.classList.remove('active');\n            log('‚èπÔ∏è Listening stopped', 'info');\n        }\n        \n        function stopListening() {\n            isListening = false;\n        }\n        \n        async function recordAndProcess() {\n            try {\n                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n                const mediaRecorder = new MediaRecorder(stream);\n                const chunks = [];\n                \n                mediaRecorder.ondataavailable = e => chunks.push(e.data);\n                \n                const recordingPromise = new Promise((resolve) => {\n                    mediaRecorder.onstop = async () => {\n                        stream.getTracks().forEach(t => t.stop());\n                        \n                        if (isSpeaking) {\n                            resolve();\n                            return;\n                        }\n                        \n                        const audioBlob = new Blob(chunks, { type: 'audio/webm' });\n                        const formData = new FormData();\n                        formData.append('audio', audioBlob, 'recording.webm');\n                        \n                        log('üì§ Sending audio...', 'debug');\n                        \n                        try {\n                            const response = await fetch('/process_voice', {\n                                method: 'POST',\n                                body: formData\n                            });\n                            \n                            const data = await response.json();\n                            \n                            if (data.transcription) {\n                                log(`üëÇ Heard: \"${data.transcription}\"`, 'info');\n                                if (data.transcription !== '(unclear audio)') {\n                                    addChat('user', data.transcription);\n                                }\n                            }\n                            \n                            if (data.reply) {\n                                log(`ü§ñ Reply: \"${data.reply.substring(0, 50)}...\"`, 'info');\n                                addChat('ai', data.reply);\n                                \n                                if (data.audio_url) {\n                                    await playAudio(data.audio_url);\n                                }\n                            }\n                            \n                            if (data.mode) {\n                                statusMode.textContent = `Mode: ${data.mode.toUpperCase()}`;\n                            }\n                            \n                            if (data.now_playing) {\n                                nowPlaying.style.display = 'block';\n                                document.getElementById('song-title').textContent = data.now_playing.title;\n                                document.getElementById('song-link').href = data.now_playing.url;\n                            }\n                        } catch (err) {\n                            log(`Backend error: ${err.message}`, 'error');\n                        }\n                        \n                        resolve();\n                    };\n                });\n                \n                mediaRecorder.start();\n                setTimeout(() => mediaRecorder.stop(), 3500);\n                \n                await recordingPromise;\n            } catch (err) {\n                log(`Microphone error: ${err.message}`, 'error');\n                throw err;\n            }\n        }\n        \n        function playAudio(url) {\n            return new Promise((resolve) => {\n                isSpeaking = true;\n                visualizer.classList.remove('listening');\n                log('üîä Playing TTS (Mic Paused)', 'warn');\n                \n                const audio = new Audio(url);\n                \n                audio.onended = () => {\n                    isSpeaking = false;\n                    if (isListening) {\n                        visualizer.classList.add('listening');\n                    }\n                    log('‚úÖ TTS finished (Mic Resumed)', 'info');\n                    resolve();\n                };\n                \n                audio.onerror = (err) => {\n                    log(`Audio error: ${err}`, 'error');\n                    isSpeaking = false;\n                    resolve();\n                };\n                \n                audio.play().catch(e => {\n                    log(`Playback failed: ${e}`, 'error');\n                    isSpeaking = false;\n                    resolve();\n                });\n            });\n        }\n        \n        btnListen.addEventListener('click', startListening);\n        btnStop.addEventListener('click', stopListening);\n        \n        log('‚úÖ Frontend initialized. Say \"Hanuman\" to wake! (Fuzzy matching enabled)', 'info');\n    </script>\n</body>\n</html>\n\"\"\"\n\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\n\nif __name__ == '__main__':\n    logger.info(\"\"\"\n    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n    ‚ïë             üî± PROJECT HANUMAN - DIVINE VOICE ASSISTANT üî±                   ‚ïë\n    ‚ïë                                                                                ‚ïë\n    ‚ïë  Starting server on http://localhost:5000                                     ‚ïë\n    ‚ïë                                                                                ‚ïë\n    ‚ïë  ‚ú® NEW: FUZZY COMMAND MATCHING for ALL commands!                             ‚ïë\n    ‚ïë  Try mishearings like: \"agya\", \"hassya\", \"khoj mode\", \"rok\", etc.           ‚ïë\n    ‚ïë                                                                                ‚ïë\n    ‚ïë  Commands:                                                                    ‚ïë\n    ‚ïë  - Say \"Hanuman\" to wake up                                                  ‚ïë\n    ‚ïë  - Choose: Aagya, Hasya, Yudha, Gandharva, or Khoj                           ‚ïë\n    ‚ïë  - Say \"Help\" for detailed guide                                             ‚ïë\n    ‚ïë  - Say \"Exit\" to return to main menu                                         ‚ïë\n    ‚ïë                                                                                ‚ïë\n    ‚ïë  Jai Shri Ram! üôè                                                             ‚ïë\n    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n    \"\"\")\n    \n    try:\n        logger.info(f\"Starting Flask server on {CONFIG.FLASK_HOST}:{CONFIG.FLASK_PORT}\")\n        app.run(\n            host=CONFIG.FLASK_HOST,\n            port=CONFIG.FLASK_PORT,\n            debug=CONFIG.DEBUG,\n            use_reloader=False\n        )\n    except KeyboardInterrupt:\n        logger.info(\"\\nüôè Hanuman returns to meditation. Jai Shri Ram!\")\n        sys.exit(0)\n    except Exception as e:\n        logger.error(f\"Fatal error: {e}\")\n        sys.exit(1)\n", "sha": "7d3dcdeed1a8adf46e23f846ead8f16862abc211", "_tool_input_summary": "Updating main.py to add comprehensive fuzzy matching for all commands including modes (Aagya, Hasya, Yudha, Gandharva, Khoj), actions (Help, Exit), and game moves (Rock, Paper, Scissors) with fuzzy variations.", "_requires_user_approval": true}